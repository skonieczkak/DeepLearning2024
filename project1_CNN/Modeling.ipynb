{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = 9,6\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\"\"\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "INPUT_SHAPE = X_train.shape[1:]\n",
    "NUM_CLASSES=10\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "# Convert class labels to one-hot encoded\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Deepl learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=1e-3 # chosen arbitrary, tuning performed later on for further experiments\n",
    "EPOCHS=100  \n",
    "PATIENCE=10\n",
    "MIN_DELTA=0.01\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, min_delta=MIN_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model1(input_shape, \n",
    "                    num_classes, \n",
    "                    learning_rate=0.001,\n",
    "                    dropout_rate1=0.25,\n",
    "                    dropout_rate2=0.5,\n",
    "                    weight_decay=0.0001,\n",
    "                    decay_steps=100000,\n",
    "                    decay_rate=0.96):\n",
    "    \"\"\"\n",
    "    Generate Keras Sequential model according to proposed architecture (1).\n",
    "\n",
    "    Args:\n",
    "        learning_rate (float, optional): Learning rate of the neural network. Defaults to LR.\n",
    "\n",
    "    Returns:\n",
    "        Keras Sequential model, complied, ready to use (to call .fit method).\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(16, (3, 3), padding='same', kernel_regularizer=l2(weight_decay), input_shape=input_shape),\n",
    "        LeakyReLU(0.1),\n",
    "        Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "        LeakyReLU(0.1),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(dropout_rate1),\n",
    "        Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "        LeakyReLU(0.1),\n",
    "        Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)),\n",
    "        LeakyReLU(0.1),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(dropout_rate1),\n",
    "        Flatten(),\n",
    "        Dense(256, kernel_regularizer=l2(weight_decay)),\n",
    "        LeakyReLU(0.1),\n",
    "        Dropout(dropout_rate2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True)\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1084234 (4.14 MB)\n",
      "Trainable params: 1084234 (4.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = generate_model1(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 4, 4, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814634 (3.11 MB)\n",
      "Trainable params: 814378 (3.11 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = generate_model2()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model3(learning_rate: float = LR):\n",
    "    \"\"\"\n",
    "    Generate Keras Sequential model according to proposed architecture (3).\n",
    "\n",
    "    Args:\n",
    "        learning_rate (float, optional): Learning rate of the neural network. Defaults to LR.\n",
    "\n",
    "    Returns:\n",
    "        Keras Sequential model, complied, ready to use (to call .fit method).\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=INPUT_SHAPE, activation='relu',))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(4,4), activation='relu',))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 29, 29, 32)        1568      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 11, 11, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 5, 5, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               102528    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131178 (512.41 KB)\n",
      "Trainable params: 131178 (512.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3=generate_model3()\n",
    "model3.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
